# Demonstrations

We provide a command line tool to download demonstrations directly from our [Hugging Face ðŸ¤— dataset](https://huggingface.co/datasets/haosulab/ManiSkill_Demonstrations) which is done by task ID. The tool will download the demonstration files to a folder and also a few demonstration videos visualizing what the demonstrations look like. See [Tasks](../../tasks/index.md) for a list of all supported tasks that have demonstrations.

<!-- TODO: add a table here detailing the data info in detail -->
<!-- Please see our [notes](https://docs.google.com/document/d/1bBKmsR-R_7tR9LwaT1c3J26SjIWw27tWSLdHnfBR01c/edit?usp=sharing) about the details of the demonstrations. -->

Demo datasets are typically stored in a minimal format (e.g., no observation data) and store env states instead to compress them. We provide a flexible tool to replay demonstration datasets to modify them e.g. add visual observation data, record videos and more, see the [trajectory replay documentation](../datasets/replay.md). If you want to generate the original compressed datasets yourself locally we save all scripts used for dataset generation in the [data_generation](https://github.com/haosulab/ManiSkill/tree/main/scripts/data_generation) folder. For users looking to benchmark imitation learning we strongly recommend following the instructions on the [imitation learning setup page](../learning_from_demos/setup.md) which details how to replay the compressed datasets for benchmarking training datasets.


## Format

All demonstrations for a task are saved in the HDF5 format openable by [h5py](https://github.com/h5py/h5py). Each HDF5 dataset is named `trajectory.{obs_mode}.{control_mode}.{sim_backend}.h5`, and is associated with a JSON metadata file with the same base name. Unless otherwise specified, `trajectory.h5` is short for `trajectory.none.pd_joint_pos.physx_cpu.h5`, which contains the original demonstrations generated by the `pd_joint_pos` controller with the `none` observation mode (empty observations) in the CPU based simulation. However, there may exist demonstrations generated by other controllers. **Thus, please check the associated JSON to ensure which controller is used.**

<!-- 
:::{note}
For `PickSingleYCB-v0`, `TurnFaucet-v0`, the dataset is named `{model_id}.h5` for each asset. It is due to some legacy issues, and might be changed in the future.

For `OpenCabinetDoor-v1`, `OpenCabinetDrawer-v1`, `PushChair-v1`, `MoveBucket-v1`, which are migrated from [ManiSkill1](https://github.com/haosulab/ManiSkill), trajectories are generated by the RL and `base_pd_joint_vel_arm_pd_joint_vel` controller.
::: -->

## Meta Information (JSON)

Each JSON file contains:

- `env_info` (Dict): task (also known as environment) information, which can be used to initialize the task
  - `env_id` (str): task id
  - `max_episode_steps` (int)
  - `env_kwargs` (Dict): keyword arguments to initialize the task. **Essential to recreate the environment.**
- `episodes` (List[Dict]): episode information
- `source_type` (Optional[str]): a simple category string describing what process generated the trajectory data.
- `source_desc` (Optional[str]): a longer explanation of how the data was generated.

The episode information (the element of `episodes`) includes:

- `episode_id` (int): a unique id to index the episode
- `reset_kwargs` (Dict): keyword arguments to reset the task. **Essential to reproduce the trajectory.**
- `control_mode` (str): control mode used for the episode.
- `elapsed_steps` (int): trajectory length
- `info` (Dict): information at the end of the episode.

With just the meta data, you can usually reproduce the task the same way it was created when the trajectories were collected as so:

```python
env = gym.make(env_info["env_id"], **env_info["env_kwargs"])
episode = env_info["episodes"][0] # picks the first
env.reset(**episode["reset_kwargs"])
```

Sometimes trajectory data is collected in GPU simulation which means the randomizations are dependent on the number of parallel environments in addition to seed. To ensure the same start state you can use the first environment state data stored in the trajectory and set the environment state accordingly.

## Trajectory Data (HDF5)

Each HDF5 demonstration dataset consists of multiple trajectories. The key of each trajectory is `traj_{episode_id}`, e.g., `traj_0`.

Each trajectory is an `h5py.Group`, which contains:

- actions: [T, A], `np.float32`. `T` is the number of transitions.
- terminated: [T], `np.bool_`. It indicates whether the task is terminated or not at each time step.
- truncated: [T], `np.bool_`. It indicates whether the task is truncated or not at each time step.
- env_states: [T+1, D], `np.float32`. Environment states. It can be used to set the environment to a certain state via `env.set_state_dict`. However, it may not be enough to reproduce the trajectory.
- success (optional): [T], `np.bool_`. It indicates whether the task is successful at each time step. Included if task defines success.
- fail (optional): [T], `np.bool_`. It indicates whether the task is in a failure state at each time step. Included if task defines failure.
- obs (optional): [T+1, D] observations.

Note that env_states is in a dictionary form (and observations may be as well depending on obs_mode), where it is formatted as a dictionary of lists. For example, a typical environment state looks like this:

:::
<!-- #### Other -->
